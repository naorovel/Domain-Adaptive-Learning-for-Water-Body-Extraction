{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rojasvel/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import  binary_cross_entropy_with_logits, sigmoid\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import from self-written code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No subfolders found in the specified input folder.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtif_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SatelliteDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MIoU\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dice_bce_loss_with_logits, dice_loss_with_logits\n",
      "File \u001b[0;32m/home/rojasvel/MM803/Domain-Adaptive-Learning-for-Water-Body-Extraction/src/tif_processor.py:759\u001b[0m\n\u001b[1;32m    757\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Style\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/CN/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 759\u001b[0m fda, no_fda \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tiles_with_fda\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiles with FDA applied: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiles without FDA applied: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_fda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/rojasvel/MM803/Domain-Adaptive-Learning-for-Water-Body-Extraction/src/tif_processor.py:341\u001b[0m, in \u001b[0;36mprocess_tiles_with_fda\u001b[0;34m(input_path, output_path, style_folder, num_folders, apply_probability)\u001b[0m\n\u001b[1;32m    339\u001b[0m subfolders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_path) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_path, f))])\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subfolders:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo subfolders found in the specified input folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Limit to the specified number of subfolders\u001b[39;00m\n\u001b[1;32m    344\u001b[0m subfolders \u001b[38;5;241m=\u001b[39m subfolders[:num_folders]\n",
      "\u001b[0;31mValueError\u001b[0m: No subfolders found in the specified input folder."
     ]
    }
   ],
   "source": [
    "from tif_processor import SatelliteDataset\n",
    "from metrics import MIoU\n",
    "from loss import dice_bce_loss_with_logits, dice_loss_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "feature_dir_train = \"../data/CN/feature_trimmed.tif\"\n",
    "label_dir_train = \"../data/CN/label_trimmed.tif\"\n",
    "feature_tiles_train = \"../data/CN/tiles/features\"\n",
    "label_tiles_train = \"../data/CN/tiles/labels\"\n",
    "feature_tiles_mergeback_train = \"../data/CN/tiles/merge/merged_feature.tif\"\n",
    "label_tiles_mergeback_train = \"../data/CN/tiles/merge/merged_label.tif\"\n",
    "\n",
    "# Test dataset\n",
    "feature_dir_test = \"../data/BZ/feature.tif\"\n",
    "label_dir_test = \"../data/BZ/label.tif\"\n",
    "feature_tiles_test = \"../data/BZ/tiles/features\"\n",
    "label_tiles_test = \"../data/BZ/tiles/labels\"\n",
    "feature_tiles_mergeback_test = \"../data/BZ/tiles/merge/merged_feature.tif\"\n",
    "label_tiles_mergeback_test = \"../data/BZ/tiles/merge/merged_label.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "shuffle=True\n",
    "EPOCHS=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= SatelliteDataset(\n",
    "feature_dir=feature_tiles_train,\n",
    "label_dir=label_tiles_train,\n",
    "weight_dir=None,\n",
    "tiles=range(0, 320),\n",
    "mu=None,\n",
    "sigma=None,\n",
    "sample=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# set up train_val ratio\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "val_size = len(dataset) - train_size\n",
    "print(train_size)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "# split train_val\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "# create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle)\n",
    "# len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SatelliteDataset(\n",
    "feature_dir=feature_tiles_test,\n",
    "label_dir=label_tiles_test,\n",
    "weight_dir=None,\n",
    "tiles=range(0, 10),\n",
    "mu=None,\n",
    "sigma=None,\n",
    "sample=None\n",
    ")\n",
    "test_loader=DataLoader(test_dataset, batch_size, shuffle)\n",
    "# print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(segmentation_mask, filename):\n",
    "    segmentation_mask_np = segmentation_mask.detach().numpy()[0,:,:]\n",
    "    segmentation_mask_np_uint8 = (segmentation_mask_np * 255).astype(np.uint8)\n",
    "    segmentation_mask_pil = Image.fromarray(segmentation_mask_np_uint8)\n",
    "    segmentation_mask_pil.save(filename)\n",
    "\n",
    "import os\n",
    "def mkpath(path: str) -> None:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(pl.LightningModule):\n",
    "    def __init__(self, arch=\"UNet\", encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=4, out_classes=1, experiment_name=\"Experiment1\", loss=\"bce\"):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.experiment_name=experiment_name\n",
    "        # Create Model\n",
    "        self.model=smp.create_model(\n",
    "            arch,\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=out_classes\n",
    "        )\n",
    "\n",
    "        self.loss=self._get_loss(loss)\n",
    "\n",
    "        # Metrics\n",
    "        self.val_miou = MIoU(2)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.val_precision = torchmetrics.Precision(task=\"binary\")\n",
    "        self.val_recall = torchmetrics.Recall(task=\"binary\")\n",
    "\n",
    "        # test_Metrics\n",
    "        self.test_miou=MIoU(2)\n",
    "        self.test_acc=torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_precision=torchmetrics.Precision(task=\"binary\")\n",
    "        self.test_recall=torchmetrics.Recall(task=\"binary\")\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer=torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss.detach(), prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Forward Pass\n",
    "        x, y = batch\n",
    "        y_hat_loss = self(x)\n",
    "        y_hat = torch.sigmoid(y_hat_loss)\n",
    "        loss = self.loss(y_hat_loss, y)\n",
    "\n",
    "        # Log Loss and Accuracy\n",
    "        self.val_acc(y_hat, y)\n",
    "        self.val_miou(y_hat, y)\n",
    "        self.val_precision(y_hat, y)\n",
    "        self.val_recall(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_precision', self.val_precision, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_recall', self.val_recall, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_miou', self.val_miou, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = torch.sigmoid(self(x))\n",
    "\n",
    "        # Log Loss and Accuracy\n",
    "        self.test_acc(y_hat, y)\n",
    "        self.test_miou(y_hat, y)\n",
    "        self.test_precision(y_hat, y)\n",
    "        self.test_recall(y_hat, y)\n",
    "        self.log('test_acc', self.test_acc, logger=True)\n",
    "        self.log('test_precision', self.test_precision, logger=True)\n",
    "        self.log('test_recall', self.test_recall, logger=True)\n",
    "        self.log('test_miou', self.test_miou, logger=True)\n",
    "\n",
    "        # Save Prediction and Label Masks\n",
    "        y = y[0,:,:,:].cpu()\n",
    "        out = y_hat[0,:,:,:].cpu()\n",
    "        mkpath(f\"predictions/{self.experiment_name}/masks\")\n",
    "        mkpath(f\"predictions/{self.experiment_name}/preds\")\n",
    "        save_mask(y.cpu(), f\"predictions/{self.experiment_name}/masks/mask_{batch_idx}.png\")\n",
    "        save_mask(out.round(), f\"predictions/{self.experiment_name}/preds/pred_{batch_idx}.png\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_loss(loss):\n",
    "        if loss == \"dice\":\n",
    "            return dice_loss_with_logits\n",
    "        elif loss == \"dice_bce\":\n",
    "            return dice_bce_loss_with_logits\n",
    "        return binary_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training_Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Experiment(experiment_name=\"Experiment0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type            | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model          | Unet            | 24.4 M | train\n",
      "1 | val_miou       | MIoU            | 0      | train\n",
      "2 | val_acc        | BinaryAccuracy  | 0      | train\n",
      "3 | val_precision  | BinaryPrecision | 0      | train\n",
      "4 | val_recall     | BinaryRecall    | 0      | train\n",
      "5 | test_miou      | MIoU            | 0      | train\n",
      "6 | test_acc       | BinaryAccuracy  | 0      | train\n",
      "7 | test_precision | BinaryPrecision | 0      | train\n",
      "8 | test_recall    | BinaryRecall    | 0      | train\n",
      "-----------------------------------------------------------\n",
      "24.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.4 M    Total params\n",
      "97.758    Total estimated model params size (MB)\n",
      "196       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5ee5d491d64727a3248ea8be82af5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Program Files\\anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "e:\\Program Files\\anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "e:\\Program Files\\anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e483757ffd5b4ae584c29d148dc8142a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6bf12bfbd54080b5ae9411616ef53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a50c1a6f8c40f6a990cec293dc177b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2329939c28f4ceca4a7a01f912b66a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0560f99abafb4b1283dbf3bdd521a908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a81cc555f04d94b6070c89a8121591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer=pl.Trainer(max_epochs=EPOCHS, log_every_n_steps=1)\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1372e5da29df4fc88261ef696055936d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'val_loss': 0.04803231358528137, 'val_acc': 0.9844863414764404, 'val_precision': 0.8115824460983276, 'val_recall': 0.6527876257896423, 'val_miou': 0.7755206823348999}]\n"
     ]
    }
   ],
   "source": [
    "# run validation dataset\n",
    "valid_metrics = trainer.validate(model, dataloaders=val_loader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Program Files\\anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "e:\\Program Files\\anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508cbbf6e8e2457abd93824eff6bb441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_acc': 0.9868423342704773, 'test_precision': 0.37917208671569824, 'test_recall': 0.40324345231056213, 'test_miou': 0.6148345470428467}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "# run test dataset\n",
    "test_metrics = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "print(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DALWBE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
